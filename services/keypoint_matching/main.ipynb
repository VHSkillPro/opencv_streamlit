{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazzu/Code/opencv_streamlit\n"
     ]
    }
   ],
   "source": [
    "%cd \"../..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pr_sift = np.load(\"./services/semantic_keypoint_detection/pr_sift.npy\")\n",
    "pr_orb = np.load(\"./services/semantic_keypoint_detection/pr_orb.npy\")\n",
    "\n",
    "pr_sift_fulls = []\n",
    "pr_orb_fulls = []\n",
    "for i in range(8):\n",
    "    pr_sift_fulls.append(\n",
    "        np.where(np.logical_and(pr_sift[i][:, 0] == 1, pr_sift[i][:, 1] == 1))[0]\n",
    "    )\n",
    "    pr_orb_fulls.append(\n",
    "        np.where(np.logical_and(pr_orb[i][:, 0] == 1, pr_orb[i][:, 1] == 1))[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from services.semantic_keypoint_detection.services import DATATYPES\n",
    "\n",
    "\n",
    "accuracy_rotations_orb = []\n",
    "orb = cv2.ORB_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "for alpha in range(0, 360, 10):\n",
    "    accuracy_orb = []\n",
    "    for i in range(8):\n",
    "        for id in pr_orb_fulls[i]:\n",
    "            # Read image\n",
    "            image = cv2.imread(os.path.join(DATATYPES[i], \"images\", f\"{id}.png\"))\n",
    "\n",
    "            # Rotate image\n",
    "            rotate_matrix = cv2.getRotationMatrix2D(\n",
    "                ((image.shape[1] - 1) / 2.0, (image.shape[0] - 1) / 2.0), alpha, 1.0\n",
    "            )\n",
    "            image_rotated = cv2.warpAffine(\n",
    "                image.copy(), rotate_matrix, (image.shape[1], image.shape[0])\n",
    "            )\n",
    "\n",
    "            # Convert to gray\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image_rotated = cv2.cvtColor(image_rotated, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect keypoints\n",
    "            original_keypoints, original_descriptions = orb.detectAndCompute(\n",
    "                gray_image, None\n",
    "            )\n",
    "\n",
    "            rotated_keypoints, rotated_descriptions = orb.detectAndCompute(\n",
    "                gray_image_rotated, None\n",
    "            )\n",
    "\n",
    "            if original_descriptions is None or rotated_descriptions is None:\n",
    "                accuracy_orb.append(0)\n",
    "            else:\n",
    "                matches = bf.match(original_descriptions, rotated_descriptions)\n",
    "                accuracy_orb.append(\n",
    "                    len(matches)\n",
    "                    / max(len(original_descriptions), len(rotated_descriptions))\n",
    "                )\n",
    "\n",
    "    accuracy_rotations_orb.append(np.mean(accuracy_orb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(0.7118986956452131), np.float64(0.6489939897771113), np.float64(0.5823726228814303), np.float64(0.5332206234121253), np.float64(0.5064483085921113), np.float64(0.46996367280269025), np.float64(0.4148382549979112), np.float64(0.4039704385149031), np.float64(0.42971605444008565), np.float64(0.4262422969221164), np.float64(0.4499190920700475), np.float64(0.48575494467455615), np.float64(0.5331637974020808), np.float64(0.5860344958867193), np.float64(0.6262579590221845), np.float64(0.6804072697603177), np.float64(0.7345108113183805), np.float64(1.0), np.float64(0.7107193768796876), np.float64(0.6459539838060709), np.float64(0.582874087835228), np.float64(0.532891067910156), np.float64(0.5045699056883001), np.float64(0.4691973892777861), np.float64(0.41414737049363926), np.float64(0.4045218411352713), np.float64(0.42971605444008565), np.float64(0.4265022668372587), np.float64(0.44934437942636946), np.float64(0.48552854272401624), np.float64(0.5346127698855359), np.float64(0.5859977223154629), np.float64(0.6278343518297612), np.float64(0.6789020699792558), np.float64(0.7335013686537654)]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rotations_orb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from services.semantic_keypoint_detection.services import DATATYPES\n",
    "\n",
    "\n",
    "accuracy_rotations_sift = []\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "for alpha in range(0, 360, 10):\n",
    "    accuracy_sift = []\n",
    "    for i in range(8):\n",
    "        for id in pr_sift_fulls[i]:\n",
    "            # Read image\n",
    "            image = cv2.imread(os.path.join(DATATYPES[i], \"images\", f\"{id}.png\"))\n",
    "\n",
    "            # Rotate image\n",
    "            rotate_matrix = cv2.getRotationMatrix2D(\n",
    "                ((image.shape[1] - 1) / 2.0, (image.shape[0] - 1) / 2.0), alpha, 1.0\n",
    "            )\n",
    "            image_rotated = cv2.warpAffine(\n",
    "                image.copy(), rotate_matrix, (image.shape[1], image.shape[0])\n",
    "            )\n",
    "\n",
    "            # Convert to gray\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image_rotated = cv2.cvtColor(image_rotated, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect keypoints\n",
    "            original_keypoints, original_descriptions = sift.detectAndCompute(\n",
    "                gray_image, None\n",
    "            )\n",
    "\n",
    "            rotated_keypoints, rotated_descriptions = sift.detectAndCompute(\n",
    "                gray_image_rotated, None\n",
    "            )\n",
    "\n",
    "            if original_descriptions is None or rotated_descriptions is None:\n",
    "                accuracy_sift.append(0)\n",
    "            else:\n",
    "                matches = bf.knnMatch(original_descriptions, rotated_descriptions, k=2)\n",
    "\n",
    "                good_matches = 0\n",
    "                for k in range(len(matches)):\n",
    "                    if len(matches[k]) == 2:\n",
    "                        if matches[k][0].distance < 0.75 * matches[k][1].distance:\n",
    "                            good_matches += 1\n",
    "\n",
    "                accuracy_sift.append(\n",
    "                    good_matches\n",
    "                    / max(len(original_descriptions), len(rotated_descriptions))\n",
    "                )\n",
    "\n",
    "    accuracy_rotations_sift.append(np.mean(accuracy_sift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.9154929577464789), np.float64(0.5540755513932812), np.float64(0.4288143492663503), np.float64(0.48731965876146754), np.float64(0.5061028206980545), np.float64(0.4701642878238831), np.float64(0.5072218355151248), np.float64(0.39305025055247683), np.float64(0.4743378143124142), np.float64(0.7020252830111985), np.float64(0.4867073895450035), np.float64(0.4171842935987961), np.float64(0.48445995820194576), np.float64(0.46629528530936987), np.float64(0.4768897573475039), np.float64(0.5152072237587652), np.float64(0.38912091805341426), np.float64(0.5417687355958626), np.float64(0.8846125705280634), np.float64(0.5329674605979494), np.float64(0.4230195750381111), np.float64(0.4961801582817151), np.float64(0.5067584813840209), np.float64(0.4763324025233719), np.float64(0.4857789047641719), np.float64(0.3813014350183353), np.float64(0.4736695892759208), np.float64(0.6868067792467129), np.float64(0.49176279395831995), np.float64(0.41616925768806085), np.float64(0.47225088135893517), np.float64(0.4793649582997902), np.float64(0.479098211233671), np.float64(0.5012615891911012), np.float64(0.3956892512879248), np.float64(0.5348013274075064)]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rotations_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\n",
    "    os.path.join(\"./services/keypoint_matching/accuracy_rotations_sift.npy\"),\n",
    "    accuracy_rotations_sift,\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(\"./services/keypoint_matching/accuracy_rotations_orb.npy\"),\n",
    "    accuracy_rotations_orb,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
