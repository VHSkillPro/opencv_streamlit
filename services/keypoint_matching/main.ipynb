{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazzu/Code/opencv_streamlit\n"
     ]
    }
   ],
   "source": [
    "%cd \"../..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pr_sift = np.load(\"./services/semantic_keypoint_detection/pr_sift.npy\")\n",
    "pr_orb = np.load(\"./services/semantic_keypoint_detection/pr_orb.npy\")\n",
    "\n",
    "pr_sift_fulls = []\n",
    "pr_orb_fulls = []\n",
    "for i in range(8):\n",
    "    pr_sift_fulls.append(\n",
    "        np.where(np.logical_and(pr_sift[i][:, 0] == 1, pr_sift[i][:, 1] == 1))[0]\n",
    "    )\n",
    "    pr_orb_fulls.append(\n",
    "        np.where(np.logical_and(pr_orb[i][:, 0] == 1, pr_orb[i][:, 1] == 1))[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from services.semantic_keypoint_detection.services import DATATYPES\n",
    "\n",
    "\n",
    "accuracy_rotations_orb = []\n",
    "orb = cv2.ORB_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "for alpha in range(0, 360, 10):\n",
    "    accuracy_orb = []\n",
    "    for i in range(8):\n",
    "        for id in pr_orb_fulls[i]:\n",
    "            # Read image\n",
    "            image = cv2.imread(os.path.join(DATATYPES[i], \"images\", f\"{id}.png\"))\n",
    "\n",
    "            # Rotate image\n",
    "            rotate_matrix = cv2.getRotationMatrix2D(\n",
    "                ((image.shape[1] - 1) / 2.0, (image.shape[0] - 1) / 2.0), alpha, 1.0\n",
    "            )\n",
    "            image_rotated = cv2.warpAffine(\n",
    "                image.copy(), rotate_matrix, (image.shape[1], image.shape[0])\n",
    "            )\n",
    "\n",
    "            # Convert to gray\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image_rotated = cv2.cvtColor(image_rotated, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect keypoints\n",
    "            original_keypoints, original_descriptions = orb.detectAndCompute(\n",
    "                gray_image, None\n",
    "            )\n",
    "\n",
    "            rotated_keypoints, rotated_descriptions = orb.detectAndCompute(\n",
    "                gray_image_rotated, None\n",
    "            )\n",
    "\n",
    "            if original_descriptions is None or rotated_descriptions is None:\n",
    "                accuracy_orb.append(0)\n",
    "            else:\n",
    "                matches = bf.match(original_descriptions, rotated_descriptions)\n",
    "                accuracy_orb.append(\n",
    "                    len(matches)\n",
    "                    / max(len(original_descriptions), len(rotated_descriptions))\n",
    "                )\n",
    "\n",
    "    accuracy_rotations_orb.append(np.mean(accuracy_orb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(0.7118986956452131), np.float64(0.6489939897771113), np.float64(0.5823726228814303), np.float64(0.5332206234121253), np.float64(0.5064483085921113), np.float64(0.46996367280269025), np.float64(0.4148382549979112), np.float64(0.4039704385149031), np.float64(0.42971605444008565), np.float64(0.4262422969221164), np.float64(0.4499190920700475), np.float64(0.48575494467455615), np.float64(0.5331637974020808), np.float64(0.5860344958867193), np.float64(0.6262579590221845), np.float64(0.6804072697603177), np.float64(0.7345108113183805), np.float64(1.0), np.float64(0.7107193768796876), np.float64(0.6459539838060709), np.float64(0.582874087835228), np.float64(0.532891067910156), np.float64(0.5045699056883001), np.float64(0.4691973892777861), np.float64(0.41414737049363926), np.float64(0.4045218411352713), np.float64(0.42971605444008565), np.float64(0.4265022668372587), np.float64(0.44934437942636946), np.float64(0.48552854272401624), np.float64(0.5346127698855359), np.float64(0.5859977223154629), np.float64(0.6278343518297612), np.float64(0.6789020699792558), np.float64(0.7335013686537654)]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rotations_orb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from services.semantic_keypoint_detection.services import DATATYPES\n",
    "\n",
    "\n",
    "accuracy_rotations_sift = []\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "for alpha in range(0, 360, 10):\n",
    "    accuracy_sift = []\n",
    "    for i in range(8):\n",
    "        for id in pr_sift_fulls[i]:\n",
    "            # Read image\n",
    "            image = cv2.imread(os.path.join(DATATYPES[i], \"images\", f\"{id}.png\"))\n",
    "\n",
    "            # Rotate image\n",
    "            rotate_matrix = cv2.getRotationMatrix2D(\n",
    "                ((image.shape[1] - 1) / 2.0, (image.shape[0] - 1) / 2.0), alpha, 1.0\n",
    "            )\n",
    "            image_rotated = cv2.warpAffine(\n",
    "                image.copy(), rotate_matrix, (image.shape[1], image.shape[0])\n",
    "            )\n",
    "\n",
    "            # Convert to gray\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray_image_rotated = cv2.cvtColor(image_rotated, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect keypoints\n",
    "            original_keypoints, original_descriptions = sift.detectAndCompute(\n",
    "                gray_image, None\n",
    "            )\n",
    "\n",
    "            rotated_keypoints, rotated_descriptions = sift.detectAndCompute(\n",
    "                gray_image_rotated, None\n",
    "            )\n",
    "\n",
    "            if original_descriptions is None or rotated_descriptions is None:\n",
    "                accuracy_sift.append(0)\n",
    "            else:\n",
    "                matches = bf.match(original_descriptions, rotated_descriptions)\n",
    "\n",
    "                # good_matches = 0\n",
    "                # for k in range(len(matches)):\n",
    "                #     if len(matches[k]) == 2:\n",
    "                #         if matches[k][0].distance < 0.75 * matches[k][1].distance:\n",
    "                #             good_matches += 1\n",
    "\n",
    "                accuracy_sift.append(\n",
    "                    len(matches)\n",
    "                    / max(len(original_descriptions), len(rotated_descriptions))\n",
    "                )\n",
    "\n",
    "    accuracy_rotations_sift.append(np.mean(accuracy_sift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(0.7178840215294234), np.float64(0.5934762435588593), np.float64(0.6968441162659103), np.float64(0.7022090282353878), np.float64(0.700128314806944), np.float64(0.6772326828561296), np.float64(0.5306231042522277), np.float64(0.642743634619425), np.float64(0.7700695465815599), np.float64(0.6771707418973368), np.float64(0.5615641748276554), np.float64(0.6740924196299639), np.float64(0.6235028273760669), np.float64(0.670448565518988), np.float64(0.6589999043553963), np.float64(0.5475350603178032), np.float64(0.696981033968672), np.float64(0.956118529357966), np.float64(0.7060334239083206), np.float64(0.5791748725763501), np.float64(0.7086376394382324), np.float64(0.6922701091284574), np.float64(0.7089708942442996), np.float64(0.6624140896186212), np.float64(0.5259435114403322), np.float64(0.6344661002234149), np.float64(0.753146370337754), np.float64(0.6880778765099395), np.float64(0.568413023617624), np.float64(0.6743283769675869), np.float64(0.6383578048089886), np.float64(0.673604557552362), np.float64(0.6747014694535735), np.float64(0.5454813587398626), np.float64(0.7067986492860038)]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rotations_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\n",
    "    os.path.join(\"./services/keypoint_matching/accuracy_rotations_sift.npy\"),\n",
    "    accuracy_rotations_sift,\n",
    ")\n",
    "# np.save(\n",
    "#     os.path.join(\"./services/keypoint_matching/accuracy_rotations_orb.npy\"),\n",
    "#     accuracy_rotations_orb,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
